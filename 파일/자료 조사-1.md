<h1>기존 어플리케이션 문제점</h1>
<p>
1. 차량 사진을 찍는 부분이 있었지만 결함 존재의 여부는 직접 눈으로 꼼꼼히 확인하지 않으면 모른다. 이는 번거로운 과정이라 대충 넘기는 경우가 많다.<br>
2. 이전 사용자가 만든 결함을 다음 사용자가 억울하게 보상해야 하는 사례가 많다.<br>
3. 현재 업체에서는 검수 관리자가 직접 눈으로 검수하거나 신고시에만 자세히 모니터링 하는 형태로 진행하고 있다. 그러나 이것은 시간과 비용적 측면에서 업체의 큰 부담이 된다.<br>
</p>

<h1>실시간 객체 탐지를 요구하는 object detection 종류</h1>
<p>
<h3>YOLO(You Only Look Once)</h3><br>
•	특징: 이미지를 그리드로 나눈 후, 각 그리드 셀에서 객체의 경계 상자와 클래스 확률을 동시에 예측한다. 이를 통해 한 번의 전방향 패스로 객체를 탐지할 수 있어 빠르고 실시간 처리에 적합하다.<br>
•	장점: 높은 속도와 실시간 객체 감지를 제공한다.<br>
•	단점: 작은 객체나 밀집된 객체를 감지하는 데에는 다소 어려움이 있을 수 있다.<br>
<h3>SSD(Single Shot MultiBox Detector)</h3><br>
•	특징: 단일 신경망을 사용하여 다양한 크기의 특징 맵을 생성하고 이를 통해 다양한 크기와 종류의 객체를 감지하는 방식으로, 다양한 크기의 객체를 효과적으로 감지할 수 있다.<br>
•	장점: 다양한 크기의 객체에 대해 강건하게 동작하며, 높은 성능을 제공한다.<br>
•	단점: YOLO보다는 더 많은 계산 리소스가 필요하며, 속도 측면에서는 YOLO에 비해 약간 느릴 수 있다.<br>
<h3>RetinaNet</h3><br>
•	특징: 객체 감지에서 발생하는 클래스 불균형 문제를 해결하기 위해 설계되었다. 이 알고리즘은 Focal Loss라는 새로운 손실 함수를 도입하여 드문 클래스에 대한 강도를 조절하고 객체 감지 정확도를 향상시킨다.<br>
•	장점: 드문 클래스에 대한 감지 성능이 우수하며, 다른 알고리즘보다 더 정확한 결과를 제공할 수 있다.<br>
•	단점: 다른 알고리즘에 비해 계산 비용이 높을 수 있다.<br>
요약<br>
YOLO는 높은 속도와 실시간 처리에 적합하며, SSD는 다양한 크기의 객체에 대해 강건하게 동작하고, RetinaNet은 클래스 불균형 문제를 해결하여 드문 클래스에 대한 감지 성능을 향상시킬 수 있다.<br>
</p>

<h1>YOLO</h1><br>
<p>
<h3>장점</h3><br>
1. 높은 속도<br>
- YOLO는 복잡한 파이프라인을 사용하지 않고 회귀 문제로 인식을 수행하기 때문에 매우 빠르다.<br>
2. 향상된 정확성<br>
- YOLO는 전체 이미지를 고려하여 예측을 수행한다. 이는 훈련 및 테스트 시간 동안 전체 이미지를 보므로 클래스에 대한 컨텍스트 정보뿐만 아니라 클래스의 모양도 암시적으로 인코딩하기 때문이다.<br>
3. 뛰어난 일반화 성능<br>
- 매우 일반화 가능하므로 새로운 도메인이나 예상치 못한 입력에 적용될 때 오류 가능성이 낮다.<br>
<h3>한계점</h3><br>
- 작은 객체의 정확한 위치를 지정하는 데 어려움을 겪는다.<br>
<h3>요약</h3><br>
YOLO는 한 번의 전방향 패스로 객체를 예측하는 알고리즘으로 빠른 속도와 높은 정확성, 일반화 성능을 제공한다. 그러나 작은 객체의 정확한 위치 지정에는 어려움이 있을 수 있다.<br><br>

<h3>YOLO 과정</h3><br>
1. 입력 이미지를 사전에 정해진 크기로 변환한다.<br>
2. 이미지를 YOLO 네트워크에 입력합니다.<br>
3. 네트워크는 이미지를 여러 격자로 분할한다.<br>
4. 각 격자 셀에서 객체를 검출하고 분류한다.<br>
5. 각 객체에 대한 바운딩 박스와 클래스 정보를 예측한다.<br>
6. 겹치는 바운딩 박스를 걸러내고, 가장 높은 신뢰도 점수를 가진 객체를 선택한다.<br>
7. 최종 객체 감지 결과를 출력한다.<br>
</p>

적은 수의 이미지 데이터를 가지고 Neural Network를 훈련할 때 과적합 (overfitting) 문제가 발생할 수 있다.<br>
또한 훈련에 사용되는 이미지가 적기 때문에 훈련 과정에서 보지 못한 유형의 이미지를 인식하지 못할 수 있다.<br>
과적합 : 훈련에 사용되는 이미지에 과도하게 학습되어서 새로운 이미지를 제대로 인식하지 못하는 현상<br>

과적합 방지하기 위해 데이터를 수집하거나 데이터를 증강하여 훈련 데이터의 다양성을 확보한다.<br>

<h1>웹 데이터 수집</h1><br>
<p>
웹 크롤링<br>
- 웹 페이지 링크를 수집<br>
- 웹 페이지에서 특정 정보를 수집하는 기술<br><br>

<h3>웹 크롤링 과정</h3><br>
1.	웹 페이지 요청: 크롤링하려는 웹 사이트의 주소(URL)에 HTTP 요청을 보낸다. 이를 통해 웹 서버로부터 해당 웹 페이지의 HTML 문서를 받아온다.<br>
2.	HTML 분석: 받아온 HTML 문서를 분석하여 웹 페이지의 구조와 내용을 이해한다. 이때 웹 페이지의 제목, 본문 텍스트, 링크, 이미지 등의 요소를 식별한다.<br>
3.	데이터 추출: 필요한 정보를 추출한다. 이를 위해 정규 표현식, CSS 선택자, XPath 등의 도구를 사용하여 웹 페이지에서 원하는 데이터를 식별하고 추출한다.<br>
4.	데이터 가공: 추출된 데이터를 적절한 형식으로 가공하고 정제한다. 이때 데이터를 필터링하거나 정규화하여 원하는 형식으로 변환한다.<br>
5.	데이터 저장: 가공된 데이터를 저장한다. 이를 위해 데이터베이스에 저장하거나 텍스트 파일, CSV 파일 등의 형식으로 저장할 수 있다.<br>
6.	반복 및 자동화: 위의 과정을 반복하고 자동화하여 여러 웹 페이지에서 데이터를 수집한다. 이를 통해 대량의 데이터를 효율적으로 수집할 수 있다.<br>
</p>

<h1>이미지 어그멘테이션(Image augmentation)</h1><br>
- 원본 이미지에 아주 약간의 변형을 주어서 데이터의 고유 특성은 유지한 채로 데이터 양을 늘리는 기법이다.<br>
<p>
<h3>이미지 어그멘테이션 종류</h3><br>
1. 회전 : 이미지를 임의의 각도로 회전시켜 다양한 방향에서의 객체를 학습한다.<br>
2. 반전 : 이미지를 수평 또는 수직으로 뒤집어 객체의 위치를 변경하여 데이터의 다양성을 증가시킨다.<br>
3. 이동 : 이미지를 수평 또는 수직으로 이동시켜 다양한 시점에서의 이미지를 생성한다.<br>
4. 크기 조정 : 이미지의 크기를 변경하여 다양한 크기의 객체에 대한 학습을 개선한다.<br>
5. 크롭 : 이미지의 일부 영역을 잘라내어 특정 부분에 집중하여 학습을 개선한다.<br>
6. 추가 : 이미지에 노이즈를 추가하여 모델이 노이즈에 강인한 성능을 갖도록 한다.<br>
7. 색상 변환 : 이미지의 색상을 변환하여 다양한 환경에서의 색상 변화에 대응할 수 있도록 한다.<br>
8. 화질 조정 : 이미지의 화질을 조정하여 다양한 환경에서의 이미지를 모방한다.<br>
</p>

<h1>이미지 해싱</h1><br>
- 이미지를 고유한 해시 코드로 변환하는 기술이다. 이를 통해 이미지를 비교하고 유사성을 판단할 수 있다.<br>
<p>
이미지 해싱 단계<br>
1. 이미지 불러오기: 대상 이미지를 불러온다.<br>
2. 이미지 전처리: 이미지를 사전 처리하여 일관된 형식으로 변환한다. 이는 이미지의 크기 조정, 색상 변환, 노이즈 제거 등의 작업이 포함된다.<br>
3. 이미지 특징 추출: 이미지의 특징을 추출하여 해시 코드를 생성한다. 이미지 해싱 알고리즘은 이미지의 주요 특징을 나타내는 특징 벡터를 생성하고, 이를 바탕으로 해시 코드를 생성한다.<br>
4. 해시 코드 생성: 추출된 이미지 특징을 해싱 알고리즘에 입력하여 이미지의 고유한 해시 코드를 생성한다. 이 해시 코드는 일반적으로 고정된 길이의 이진 형식으로 표현된다.<br>
5. 해시 코드 비교: 생성된 해시 코드를 사용하여 이미지를 비교하고 유사성을 판단한다.<br><br>

<예시 코드><br>
from PIL import Image
import imagehash

# 이미지 불러오기
image_path = "example_image.jpg"
image = Image.open(image_path)

# 이미지 전처리 (크기 조정 등)
image = image.resize((8, 8), Image.ANTIALIAS)

# 이미지 특징 추출 및 Average Hash 알고리즘을 사용하여 이미지 해시 코드를 생성
# 생성된 해시 코드는 이미지의 고유한 특징을 나타내며, 이미지 간의 유사성을 판단하는 데 사용될 수 있음
hash_code = imagehash.average_hash(image)

print("Image Hash:", hash_code)
</p>

<h1>사용자가 찍은 사진이 흔들린 상태거나, 어두운 곳에서 촬영된 이미지의 경우 고려</h1><br>
<p>
1. 흔들린 이미지 - Python과 OpenCV를 사용하여 모션 블러링 전처리 진행<br>
- 모션 블러링(Motion Blurring)은 이미지에서 움직임을 감지하는 효과를 주는 전처리 기법 중 하나이다. <br>       
- 일반적으로 이미지에서 움직이는 물체의 흔들림을 흐리게 만들어주는 효과를 제공한다.<br><br>
<예시 코드>
import cv2
import numpy as np

def motion_blur(image, size=15):
    
    # 모션 블러링 커널 생성
    kernel_motion_blur = np.zeros((size, size))
    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)
    kernel_motion_blur = kernel_motion_blur / size

    # 이미지에 모션 블러링 적용
    motion_blurred = cv2.filter2D(image, -1, kernel_motion_blur)

    return motion_blurred

# 이미지 불러오기
image_path = "example_image.jpg"
image = cv2.imread(image_path)

# 모션 블러링 적용
blurred_image = motion_blur(image, size=15)

# 결과 이미지 저장
cv2.imwrite("motion_blurred_image.jpg", blurred_image)

# 결과 이미지를 화면에 표시
cv2.imshow("Motion Blurred Image", blurred_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
</p>
<p>
2. 어두운 곳에서 촬영된 이미지 - OpenCV를 사용하여 밝기와 대비를 조정<br>
<예시 코드>
import cv2
import numpy as np

def adjust_brightness_contrast(image, brightness=0, contrast=0):
    
    # 밝기 조정
    if brightness != 0:
        if brightness > 0:
            shadow = brightness
            highlight = 255
        else:
            shadow = 0
            highlight = 255 + brightness
        alpha_b = (highlight - shadow) / 255
        gamma_b = shadow

        # 밝기 조정 변환 매트릭스 생성
        buf = cv2.addWeighted(image, alpha_b, image, 0, gamma_b)
    else:
        buf = image.copy()

    # 대비 조정
    if contrast != 0:
        f = 131 * (contrast + 127) / (127 * (131 - contrast))
        alpha_c = f
        gamma_c = 127 * (1 - f)

        # 대비 조정 변환 매트릭스 생성
        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)

    return buf

# 이미지 불러오기
image_path = "example_image.jpg"
image = cv2.imread(image_path)

# 밝기와 대비 조정
adjusted_image = adjust_brightness_contrast(image, brightness=50, contrast=20)

# 결과 이미지 저장
cv2.imwrite("adjusted_image.jpg", adjusted_image)

# 결과 이미지를 화면에 표시
cv2.imshow("Adjusted Image", adjusted_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
</p>